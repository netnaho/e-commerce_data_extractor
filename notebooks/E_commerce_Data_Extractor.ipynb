{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj2O1MwZcw8r",
        "outputId": "1978ccfd-a02b-4137-e147-d919f7e4b8d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your phone (or bot token): +251 71 797 5091\n",
            "Please enter the code you received: 66341\n",
            "Signed in successfully as Netnaho; remember to not break the ToS or you will risk an account ban!\n",
            "Scraping channel: nevacomputer...\n",
            "-> Found 150 messages.\n",
            "Scraping channel: Shewabrand...\n",
            "-> Found 424 messages.\n",
            "Scraping channel: kuruwear...\n",
            "-> Found 233 messages.\n",
            "Scraping channel: Leyueqa...\n",
            "-> Found 271 messages.\n",
            "Scraping channel: AwasMart...\n",
            "-> Found 248 messages.\n",
            "\n",
            "Scraping complete! Data saved to telegram_data.csv\n",
            "        channel  message_id  \\\n",
            "0  nevacomputer        8779   \n",
            "1  nevacomputer        8774   \n",
            "2  nevacomputer        8772   \n",
            "3  nevacomputer        8770   \n",
            "4  nevacomputer        8767   \n",
            "\n",
            "                                                text  \\\n",
            "0  **ğŸ’» Dell Precision Workstation**\\n\\nA powerful...   \n",
            "1  **LENOVO X1 YOGA\\nProcessor**: 11thâ€‘Gen Intel ...   \n",
            "2  **ğŸ”¥ Acer Nitro 5 â€“ Power Meets Performance**\\n...   \n",
            "3  **ğŸ’¼ Lenovo ThinkPad X1 Extreme Gen 2 â€“ Power M...   \n",
            "4  **HP Envy x360 14â€ (14-es1013dx) â€“ Sleek 2-in-...   \n",
            "\n",
            "                       date  views  \\\n",
            "0 2025-06-21 06:32:27+00:00    879   \n",
            "1 2025-06-11 13:56:52+00:00   1835   \n",
            "2 2025-06-09 21:37:09+00:00   1709   \n",
            "3 2025-06-04 08:36:54+00:00   2260   \n",
            "4 2025-06-04 06:06:15+00:00   1812   \n",
            "\n",
            "                                        text_cleaned  \n",
            "0  **ğŸ’» Dell Precision Workstation**  A powerful p...  \n",
            "1  **LENOVO X1 YOGA Processor**: 11thâ€‘Gen Intel C...  \n",
            "2  **ğŸ”¥ Acer Nitro 5 â€“ Power Meets Performance**  ...  \n",
            "3  **ğŸ’¼ Lenovo ThinkPad X1 Extreme Gen 2 â€“ Power M...  \n",
            "4  **HP Envy x360 14â€ (14-es1013dx) â€“ Sleek 2-in-...  \n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "from telethon.sync import TelegramClient\n",
        "import asyncio\n",
        "\n",
        "# This is a special command for Colab/Jupyter to handle asynchronous code\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "# --- Configuration: PASTE YOUR CREDENTIALS HERE ---\n",
        "api_id = 7689098 # Replace with your actual api_id\n",
        "api_hash = '4fd7by65541e14aa245508aed3e90098b4c9bf0' # Replace with your actual api_hash\n",
        "phone = '+251 76 097 5094' # Replace with your phone number in international format\n",
        "\n",
        "# --- List of target channels ---\n",
        "# Public channels are identified by their username (e.g., t.me/shageronlinestore)\n",
        "channel_usernames = ['nevacomputer', 'Shewabrand', 'kuruwear', 'Leyueqa', 'AwasMart']\n",
        "\n",
        "# --- Main Scraping Function ---\n",
        "async def scrape_channel_data(client, channel_username):\n",
        "    \"\"\"Scrapes messages from a single Telegram channel.\"\"\"\n",
        "    messages_data = []\n",
        "    try:\n",
        "        # We use client.iter_messages to get all messages. We limit to 200 for this example.\n",
        "        # For your project, you might want more, but start small to test.\n",
        "        async for message in client.iter_messages(channel_username, limit=500):\n",
        "            # We only want messages that contain text.\n",
        "            if message.text:\n",
        "                messages_data.append({\n",
        "                    'channel': channel_username,\n",
        "                    'message_id': message.id,\n",
        "                    'text': message.text,\n",
        "                    'date': message.date,\n",
        "                    'views': message.views\n",
        "                })\n",
        "    except Exception as e:\n",
        "        print(f\"Error scraping {channel_username}: {e}\")\n",
        "    return messages_data\n",
        "\n",
        "# --- Main execution block ---\n",
        "async def main():\n",
        "    all_channel_data = []\n",
        "    # The 'with' statement ensures you are properly connected and disconnected.\n",
        "    async with TelegramClient('anon', api_id, api_hash) as client:\n",
        "        # When you run this for the first time, it will ask for your phone number,\n",
        "        # a login code sent to your Telegram app, and possibly your 2FA password.\n",
        "        for channel in channel_usernames:\n",
        "            print(f\"Scraping channel: {channel}...\")\n",
        "            data = await scrape_channel_data(client, channel)\n",
        "            all_channel_data.extend(data)\n",
        "            print(f\"-> Found {len(data)} messages.\")\n",
        "\n",
        "    # --- Convert to a pandas DataFrame (like a super-powered table) ---\n",
        "    df = pd.DataFrame(all_channel_data)\n",
        "\n",
        "    # --- Basic Cleaning ---\n",
        "    # A simple way to clean text is to remove newlines for better processing later.\n",
        "    df['text_cleaned'] = df['text'].str.replace(r'\\n', ' ', regex=True)\n",
        "\n",
        "    # --- Save the data to a file ---\n",
        "    # This saves your data in Colab's temporary storage.\n",
        "    df.to_csv('telegram_data.csv', index=False, encoding='utf-8-sig')\n",
        "\n",
        "    print(\"\\nScraping complete! Data saved to telegram_data.csv\")\n",
        "    # Display the first 5 rows of your table\n",
        "    print(df.head())\n",
        "\n",
        "# --- Run the scraper ---\n",
        "# This setup allows the async code to run properly.\n",
        "loop = asyncio.get_event_loop()\n",
        "loop.run_until_complete(main())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vxIehlv9fU9c",
        "outputId": "62ca2725-a796-46db-e3b3-5dbc3f19a00a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- MESSAGE 1 ---\n",
            "NIKE AIR NBA Size 40#41#42#43 MADE IN VIETNAM SHEWA BRAND áŠ á‹µáˆ«áˆ» á‹µáˆ¬á‹³á‹‹ áŠ áˆ¸á‹‹ áˆšáŠ“ áˆ…áŠ•áƒ 1áŠ› áá‰… áˆ‹á‹­ áŠ¥áŠ•áŒˆáŠ›áˆˆáŠ•  á‹¨á‰´áˆŒáŒáˆ«áˆ á‰»áŠ“áˆ‹á‰½áŠ•áŠ• á‹­á‰€áˆ‹á‰€áˆ‰ ğŸ‘‡ğŸ‘‡ğŸ‘‡ https://t.me//shewabrand https://t.me//shewabrand https://t.me//shewabrand https://t.me//shewabrand á‹¨á‰¤á‰µ á‰áŒ¥áˆ­ 109 áŠ¥áŠ“ 110 ğŸ“©á‰  inboxÂ  @shewat2 áŠ á‹‹áˆ©áŠ•  ğŸ“ 0987336458 ğŸ“0948595409 á‹­á‹°á‹áˆ‰áˆáŠ•\n",
            "\n",
            "--- MESSAGE 2 ---\n",
            "â‡ï¸Inima Electric coffee and herbs grinder\n",
            "\n",
            "--- MESSAGE 3 ---\n",
            "100% áŠ•á á‰†á‹³ á‹¨á‰°áˆ°áˆ© áŒ«áˆ›á‹á‰½ ğŸ‡ªğŸ‡¹ á‹¨áˆ€áŒˆáˆ«á‰½áŠ• áˆáˆ­á‰µ ğŸ‡ªğŸ‡¹ Â Â Â Â  ğŸ”¥1400 á‰¥áˆ­ á‰¥á‰»ğŸ”¥ â˜ï¸ 0911871330 ğŸ¢á‰¦áˆŒ áˆ˜á‹°áˆáŠ•á‹«áˆˆáˆ áŠ¦áˆ®áˆšá‹« áˆ…áŠ•áƒ 1áŠ› áá‰… 104 á‰áŒ¥áˆ­ Â Â Â Â Â Â Â Â Â Â Â Â  áŠ©áˆ© áŒ«áˆ› á‹¨á‰´áˆŒáŒáˆ«áˆ áŠ á‰£áˆ á‹­áˆáŠ‘ T.me/kuruwear ğŸ‘‰ Code 251\n",
            "\n",
            "--- MESSAGE 4 ---\n",
            "ğŸ¥‡ğŸ¥‡á‹¨áˆµáŒ‹ áˆ˜áˆá‰» áˆˆáŠáŒ­ áˆ½áŠ•áŠ©áˆ­á‰µ áˆ›á‹µá‰€á‰‚á‹« áˆˆáŠ á‰µáŠ•á‰µ áˆ˜áŠ¨á‰µáŠ¨á‰»Â  Multipurpose alloy axe Meat axe Loose meat hammer Kitchen tools Steak hammer Kitchen multifunctional hammer Â  PriceğŸ’¸ 699 Â  ğŸ T.me/Leyueqa ğŸ™‚á‰»áŠ“áˆ‹á‰½áŠ•áŠ• áˆˆáŒ“á‹°áŠ›á‹ áˆ¸áˆ­ áˆ›á‹µáˆ¨áŒá‹áŠ• áŠ á‹­áˆ­áˆ± Â Â Â Â Â Â Â Â Â Â Â  Â Â Â Â Â Â Â Â Â Â Â  0933334444 @LeMazez_z  Â Â Â Â Â Â Â Â Â Â Â  0944109295 @Lemaze_z Â Â Â Â Â Â Â Â Â Â Â  0946242424 @Le_Mazez\n",
            "\n",
            "--- MESSAGE 5 ---\n",
            "ğŸ”´ğŸ”´ğŸ”´á‹¨á‹‰áˆƒ áˆ›áŒ£áˆªá‹« áˆ´áˆ«áˆšáŠ­  **áŠáˆá‰°áˆ­ áˆ˜á‰€á‹¨áˆªá‹«** **Water Filter Dome Filter, Ceramic Dome Replacement Water Filter, Ceramic Filter Cartidge.**  á‹‹áŒ‹ 700  á‰ á‰°áŒ¨áˆ›áˆª #áŠ¨_1000_á‰¥áˆ­ á‰ áˆ‹á‹­ á‹¨áˆ†áŠ‘ #áˆáˆˆá‰µ_á‹•á‰ƒá‹á‰½ á‰ áŠ áŠ•á‹µá‹²áˆŠá‰¨áˆª áŒá‹œÂ  áˆ²á‹«á‹™ áˆµáŒ¦á‰³ áŠ¥áŠ•áˆáŠ­áˆˆá‹á‰³áˆˆáŠ•  ğŸ T.me/Leyueqa ğŸ‘ˆá‰»áŠ“áˆ‹á‰½áŠ•áŠ• áˆˆáŒ“á‹°áŠ›á‹ áˆ¸áˆ­ áˆ›á‹µáˆ¨áŒá‹áŠ• áŠ á‹­áˆ­áˆ±  Â Â Â Â Â Â Â Â Â Â Â  0933334444 @LeMazez_z Â Â Â Â Â Â Â Â Â Â Â  0944109295 @Lemaze_z Â Â Â Â Â Â Â Â Â Â Â  0946242424 @Le_Mazez\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the data we scraped\n",
        "df = pd.read_csv('telegram_data.csv')\n",
        "\n",
        "# Get a sample of 50 messages to label\n",
        "messages_to_label = df['text_cleaned'].dropna().sample(50).tolist()\n",
        "\n",
        "# Print the first 5 to see what they look like\n",
        "for i, message in enumerate(messages_to_label[:5]):\n",
        "    print(f\"--- MESSAGE {i+1} ---\\n{message}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 327,
          "referenced_widgets": [
            "8b788eb62bff4cb4a3a6ee30ce05ca13",
            "d915de30f6574d5f8c9742f9e57de5d9",
            "08e8a810a34a4b8c9e898d32dfced06b",
            "887abb3fc41c457fb3c48a490d77b7f9",
            "c8c30b7ced27453fb44782ae19464109",
            "c36b3f728fc54c5ebfcebe429ef036d7",
            "f3e04016e96d48efb724abef866ec518",
            "b7617aa30caa4cf6ba6eaa647145efb3",
            "8dba30dc2da543889bc928acb2002198",
            "6a55617ec7434d49bf378f07d36459dd",
            "50b109675799468c9fbf542721d8cbf2"
          ]
        },
        "id": "37xiHVE5tuVG",
        "outputId": "684da12e-f147-423f-815e-e38582b53b00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b788eb62bff4cb4a3a6ee30ce05ca13",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/3465 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of XLMRobertaForTokenClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/tmp/ipython-input-1-2923664662.py:136: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting model fine-tuning...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4' max='1085' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [   4/1085 00:46 < 6:59:38, 0.04 it/s, Epoch 0.01/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset, Dataset\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, TrainingArguments, Trainer, DataCollatorForTokenClassification\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score\n",
        "\n",
        "# --- 1. Load your labeled data ---\n",
        "# Manually load data from the train.txt file\n",
        "def load_data_from_txt(file_path):\n",
        "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "        lines = f.readlines()\n",
        "\n",
        "    data = []\n",
        "    tokens = []\n",
        "    ner_tags = []\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            if tokens:\n",
        "                data.append({\"tokens\": tokens, \"ner_tags\": ner_tags})\n",
        "                tokens = []\n",
        "                ner_tags = []\n",
        "        else:\n",
        "            # Assuming the format is \"token tag\"\n",
        "            parts = line.split()\n",
        "            if len(parts) >= 2: # Check if the line has at least a token and a tag\n",
        "                tokens.append(parts[0])\n",
        "                # Convert string tags to integer IDs\n",
        "                ner_tags.append(label2id[parts[1]])\n",
        "            # Optionally, handle lines with only a token or other unexpected formats\n",
        "            # else:\n",
        "            #     print(f\"Skipping malformed line: {line}\")\n",
        "\n",
        "\n",
        "    # Add the last sequence if the file doesn't end with a newline\n",
        "    if tokens:\n",
        "         data.append({\"tokens\": tokens, \"ner_tags\": ner_tags})\n",
        "\n",
        "    return data\n",
        "\n",
        "# Define your label list and mappings\n",
        "label_list = ['O', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-PER', 'I-PER', 'B-TTL', 'I-TTL', 'B-TIME', 'I-TIME']\n",
        "label2id = {l: i for i, l in enumerate(label_list)}\n",
        "id2label = {i: l for i, l in enumerate(label_list)}\n",
        "\n",
        "\n",
        "# Load the data from the local file\n",
        "raw_data = load_data_from_txt('train.txt')\n",
        "\n",
        "# Create a Hugging Face Dataset from the loaded data\n",
        "raw_datasets = Dataset.from_dict({\n",
        "    \"tokens\": [item[\"tokens\"] for item in raw_data],\n",
        "    \"ner_tags\": [item[\"ner_tags\"] for item in raw_data]\n",
        "})\n",
        "\n",
        "# The labels need to be converted from strings (e.g., \"B-Product\") to numbers (e.g., 1)\n",
        "# This step is now done within load_data_from_txt\n",
        "\n",
        "# --- 2. Tokenizer and Label Alignment ---\n",
        "# This is a critical and tricky step.\n",
        "# A model like XLM-Roberta might split a single word into multiple \"tokens\".\n",
        "# Example: \"shopping\" -> [\"shop\", \"##ping\"]\n",
        "# We need to make sure the labels align correctly with these new tokens.\n",
        "# The code below handles this by labeling only the first token of a split word and ignoring the rest.\n",
        "model_checkpoint = \"xlm-roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "    labels = []\n",
        "    for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "        previous_word_idx = None\n",
        "        label_ids = []\n",
        "        for word_idx in word_ids:\n",
        "            if word_idx is None:\n",
        "                label_ids.append(-100)\n",
        "            elif word_idx != previous_word_idx:\n",
        "                # Use the numerical label directly\n",
        "                label_ids.append(label[word_idx])\n",
        "            else:\n",
        "                label_ids.append(-100)\n",
        "            previous_word_idx = word_idx\n",
        "        labels.append(label_ids)\n",
        "    tokenized_inputs[\"labels\"] = labels\n",
        "    return tokenized_inputs\n",
        "\n",
        "# Apply this function to our whole dataset\n",
        "tokenized_datasets = raw_datasets.map(tokenize_and_align_labels, batched=True)\n",
        "\n",
        "# Rename the 'ner_tags' column to 'labels'\n",
        "# This line is no longer needed as the 'labels' column is added in tokenize_and_align_labels\n",
        "# tokenized_datasets = tokenized_datasets.rename_column(\"ner_tags\", \"labels\")\n",
        "\n",
        "\n",
        "# --- 3. Set up the Model and Trainer ---\n",
        "# Load the pre-trained model. We tell it how many labels we have.\n",
        "model = AutoModelForTokenClassification.from_pretrained(\n",
        "    model_checkpoint, num_labels=len(label_list), id2label=id2label, label2id=label2id\n",
        ")\n",
        "\n",
        "# These are the settings for the training process.\n",
        "# Think of them as configuration options for the training \"build\".\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"amharic-ner-model\",\n",
        "    eval_strategy=\"epoch\", # Check performance after each training cycle\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    num_train_epochs=5, # Go through the data 5 times. Increase for better performance if needed.\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"none\",\n",
        ")\n",
        "\n",
        "# This collator handles creating batches of data for the model.\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
        "\n",
        "# This function calculates the performance metrics (F1-score, etc.) during evaluation.\n",
        "def compute_metrics(p):\n",
        "    predictions, labels = p\n",
        "    predictions = np.argmax(predictions, axis=2)\n",
        "    true_predictions = [\n",
        "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    true_labels = [\n",
        "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "        for prediction, label in zip(predictions, labels)\n",
        "    ]\n",
        "    return {\n",
        "        \"precision\": precision_score(true_labels, true_predictions),\n",
        "        \"recall\": recall_score(true_labels, true_labels), # Corrected true_predictions to true_labels\n",
        "        \"f1\": f1_score(true_labels, true_predictions),\n",
        "    }\n",
        "\n",
        "# The Trainer object puts everything together: model, training args, data, and metrics.\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    args,\n",
        "    train_dataset=tokenized_datasets, # Use the created dataset\n",
        "    eval_dataset=tokenized_datasets, # Evaluate on the same data for this quick example\n",
        "    data_collator=data_collator,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# --- 4. START TRAINING! ---\n",
        "print(\"Starting model fine-tuning...\")\n",
        "trainer.train()\n",
        "print(\"Training complete!\")\n",
        "\n",
        "# --- 5. Save Your Model ---\n",
        "trainer.save_model(\"my_final_amharic_ner_model\")\n",
        "print(\"Model saved to 'my_final_amharic_ner_model'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08e8a810a34a4b8c9e898d32dfced06b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7617aa30caa4cf6ba6eaa647145efb3",
            "max": 3465,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8dba30dc2da543889bc928acb2002198",
            "value": 3465
          }
        },
        "50b109675799468c9fbf542721d8cbf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a55617ec7434d49bf378f07d36459dd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "887abb3fc41c457fb3c48a490d77b7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a55617ec7434d49bf378f07d36459dd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_50b109675799468c9fbf542721d8cbf2",
            "value": "â€‡3465/3465â€‡[00:01&lt;00:00,â€‡2807.39â€‡examples/s]"
          }
        },
        "8b788eb62bff4cb4a3a6ee30ce05ca13": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d915de30f6574d5f8c9742f9e57de5d9",
              "IPY_MODEL_08e8a810a34a4b8c9e898d32dfced06b",
              "IPY_MODEL_887abb3fc41c457fb3c48a490d77b7f9"
            ],
            "layout": "IPY_MODEL_c8c30b7ced27453fb44782ae19464109"
          }
        },
        "8dba30dc2da543889bc928acb2002198": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7617aa30caa4cf6ba6eaa647145efb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c36b3f728fc54c5ebfcebe429ef036d7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c8c30b7ced27453fb44782ae19464109": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d915de30f6574d5f8c9742f9e57de5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c36b3f728fc54c5ebfcebe429ef036d7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f3e04016e96d48efb724abef866ec518",
            "value": "Map:â€‡100%"
          }
        },
        "f3e04016e96d48efb724abef866ec518": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
